%\pagestyle{standardpagestyle}
%\thispagestyle{empty}
\section{Evaluation}
\label{sec:eval}
In this section, we evaluate LittlePanorama to answer the following four questions: (1) How efficient is LittleParorama? (2) Can LittlePanorama detect crash failures? (3) Can LittlePanorama detect gray failures? (4) Can LittlePanorama detect intermittent failures properly?

We evaluate LittlePanorama on failures caused by 4 bugs listed in Table ~\ref{tab:failures}. As is mentioned above, the two bugs that crash leaders/followers are introduced artificially for the purpose of demonstration. The other two that result in gray failures are bugs found in production and used in the original paper. We evaluate these bugs in an ideal way --- triggering them manually instead of simulating a production workflow. The main constraint that limits us from evaluating LittlePanorama on more bugs or in a more complex setting is the time and effort needed. 

% We use this approach to make three components observers: ZooKeeper leader, ZooKeeper follower and ZooKeeper client.




\subsection{Experiment Setup}
We use the VM provided to run all the experiments. This VM has a single-core 2.4 GHz Intel Xeon E5-2676 CPU, 1 GB of RAM and a 7.7 GB HVM disk. It runs Ubuntu 18.04 LTS (Bionic Beaver). We also modify the source code of Zookeeper version 3.4.6 to introduce hooks and artificial bugs. We evaluate LittlePanorama with a three-node Zookeeper ensemble listening on different ports.

\subsection{Performance}
\subsubsection{Reporting Speed} Table ~\ref{tab:microbench} shows the average speed of reporting an observation in LittlePanorama and Panorama respectively. Two things can be observed here. First, reporting an observation is cheap, as the average speed is less than 1 ms. This is because reporting an observation generally only incurs a local RPC. Second, LittlePanorama is about 3x faster than Panorama in terms of reporting speed. We attribute LittlePanorama's performance gain to the fact that it implements a much simpler data structure and saves everything in memory.

\begin{table}[!tb]
\begin{tabular}{p{0.24\columnwidth}p{0.33\columnwidth}p{0.33\columnwidth}}%{l|l|l}

\textbf{Operation} & \textbf{Panorama} & \textbf{LittlePanorama} \\
\midrule
  Report   &    753 $\mu$s  &  194 $\mu$s  \\
\end{tabular}
\vspace{0.5em}
\caption{Average speed of reporting an observation (Report)}
\label{tab:microbench}
\end{table}

\subsubsection{Inference Speed\label{subsubsec:inference}} Figure ~\ref{fig:inference} plots the average inference speed of LittlePanorama and Panorama with varying number of observations. LittlePanorama's performance degrades as the number of observations increases, as in the worst case it would examine all observations. However, Panorama does not have this problem. After a close inspection of Panorama's source code, we realize that this performance stability is due to the fact that Panorama only considers the two most recent observations. The original paper refers to this behavior as \textit{bounded-look-back}.

\begin{figure}[!tb]
\centering
\includegraphics[scale=0.4]{figs/inference.pdf}
\vspace{-1em}
\caption{Inference Speed
\label{fig:inference}
}
\end{figure}

\subsubsection{Propagation Delay} Figure ~\ref{fig:propagation} graphs the average delay of propagating one observation to all peers with various peer sizes. The propagation delay in both cases is proportional to the number of peers, matching what is reported in the original paper. However, looking at Panorama's source code, it seems that the authors have parallelized the process of propagation, which in theory should give a better performance. Unfortunately, we fail to observe any improvement. Our benchmark code is carefully examined such that the probability of this phenomenon caused by a bug in our code is low. Another possible explanation is that the CPU used in our experiments only has one core, burying the performance gain of thread-level parallelism.

\begin{figure}[!tb]
\centering
\includegraphics[scale=0.4]{figs/propagation.pdf}
\vspace{-1em}
\caption{Propagation Delay
\label{fig:propagation}
}
\end{figure}

\subsection{Detection of Crash Failures}
Both Panorama and LittlePanorama are designed to detect complex real-world failures. Detecting simple crash failures can serve as a sanity check on the capability of both systems. We inject two crash failures bugs --- artificial-01 and artificial-02, which will crash leader and follower respectively when triggered. Table ~\ref{tab:crashperf} shows the detection time. We see that it takes less than 200 ms to detect both failures, matching the results ($\sim$10 ms) reported in the original paper. Further, we observe little difference in performance between LittlePanorama and Panorama.

\begin{table}[!tb]
\begin{tabular}{p{0.24\columnwidth}p{0.28\columnwidth}p{0.3\columnwidth}}%{l|l|l}

\toprule
\textbf{BugId} & \textbf{Panorama} & \textbf{LittlePanorama} \\
\midrule
  artificial-01    &    128 ms  &  138 ms  \\
  artificial-02       &   81 ms   &  45 ms \\
\bottomrule
\end{tabular}
\vspace{0.5em}
\caption{Detection time for crash failures}
\label{tab:crashperf}
\end{table}

\subsection{Detection time for gray failures}
Being able to detect complex gray failures is one of the keys goals. To evaluate both systems' ability to detect gray failures, we reuse two gray failures from the original paper. They are real-world production failures found in ZooKeeper. Both of them would cause the ZooKeeper service to be temporarily unavailable but not crashing any ZooKeeper server. Table ~\ref{tab:grayperf} shows the detection time for both failures using both systems. The detection time for ZOOKEEPER-2201 and ZOOKEEPER-2247 is about 67 seconds and 2 seconds, respectively. At a first glance, one might think 67 seconds is  too long and unacceptable. In fact, this is quite expected. As is mentioned earlier in Section ~\ref{subsubsec:2201detection}, detecting ZOOKEEPER-2201 relies on connections initiated by clients timeout on the leader. The default timeout value is 30 seconds. Observing timeout from two clients would take $\sim$60 seconds. In contrast, for ZOOKEEPER-2247, all observers interacting with the leader would be able to sense its failure soon after it fails, resulting in a much shorter detection time.
 
\begin{table}[!tb]
\begin{tabular}{p{0.3\columnwidth}p{0.25\columnwidth}p{0.3\columnwidth}}%{l|l|l}

\toprule
\textbf{BugId} & \textbf{Panorama} & \textbf{LittlePanorama} \\
\midrule
  zookeeper-2201    &   66850 ms   &  67038 ms \\
  zookeeper-2247    &   2632 ms    &  2195 ms  \\
\bottomrule
\end{tabular}
\vspace{0.5em}
\caption{Detection time for gray failures}
\label{tab:grayperf}
\end{table}

\subsection{Intermittent Failures}
Finally, we test LittlePanorama's ability to detect intermittent failures using the bonus failure described in Section ~\ref{subsec:intermittent}. We instrument the cluster to hang for 2 minutes. 

Figure ~\ref{fig:transient} plots the result. The blue line at the bottom shows the actual status of the leader during the timespan of 130 seconds. This line serves as the ground truth. The orange line and green line represent the status of the leader inferred by LittlePanorama and Panorama, respectively. Both of them detect that the leader goes back to normal at time $\sim$125 seconds. It is clear that they not only are able to detect failures but also could monitor status changes in intermittent failures.

\begin{figure}[!tb]
\centering
\includegraphics[scale=0.4]{figs/transient.pdf}
\vspace{-1em}
\caption{Detection Time and Inferred Status for Intermittent Failure
\label{fig:transient}
}
\end{figure}

%%%
% Creating Testing Environment For Leader Failure
% Time To Detect Leader Failure: 128 ms

% Creating Testing Environment For Follower Failure
% Time To Detect Follower Failure: 81 ms

% Creating Testing Environment For Gray Failure 1
% Setting up nodes
% Setting up regular connections from clients
% Triggering gray 1
% Time To Detect Gray Failure 1: 66850 ms

% Creating Testing Environment For Gray Failure 2
% Triggering gray 2
% Time To Detect Gray Failure 2: 2632 ms

% Creating Testing Environment For Coming Back
% Setting up nodes
% Setting up regular connections from clients
% Triggering gray 1
% Time To Detect Failure: 66881 ms
% Start Pulling Again From Clients
% Time To Detect Revival: 125774 ms


%%% 
% Creating Testing Environment For Leader Failure
% Time To Detect Leader Failure: 138 ms

% Creating Testing Environment For Follower Failure
% Time To Detect Follower Failure: 45 ms

% Creating Testing Environment For Gray Failure 1
% Setting up nodes
% Setting up regular connections from clients
% Triggering gray 1
% Time To Detect Gray Failure 1: 67038 ms

% Creating Testing Environment For Gray Failure 2
% Triggering gray 2
% Time To Detect Gray Failure 2: 2195 ms

% Creating Testing Environment For Coming Back
% Setting up nodes
% Setting up regular connections from clients
% Triggering gray 1
% Time To Detect Failure: 66584 ms
% Start Pulling Again From Clients
% Time To Detect Revival: 125607 ms
